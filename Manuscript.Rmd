---
title: "Missing The Point"
author: "Hanne Oberman"
date: "7-9-2020"
output:
  html_document: default
  pdf_document: default
  word_document: default
bibliography: ref.bib
---

```{r setup, include=FALSE}
# environment
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(mice)
load("Data/results_25_75.Rdata")
# load data
load("Data/example.Rdata")
load("Data/example_mids.Rdata")

# sim results plotting function
simulation_plot <- function(v, name, ...){
  results %>%
    mutate(
      p = factor(p, levels = c(0.25, 0.5, 0.75), labels = c("25%", "50%", "75%")),
      mech = factor(mech, levels = c("MCAR", "MAR", "MNAR")),
      est = est - 1,
      rsq = rsq - 0.5
      ) %>% 
  ggplot(aes(
    x=.data[["it"]], 
    y=.data[[v]], 
    color = .data[["p"]], 
    shape = .data[["mech"]], 
    linetype = .data[["mech"]]
    )) +
  geom_line(na.rm = TRUE) +
  labs(
    x = "Number of iterations",
    y = name,
    color = "Incomplete \n cases", 
    shape = "Missingness \n mechanism", 
    linetype = "Missingness \n mechanism") +
  theme_classic() + 
  scale_color_manual(values = c(
    #"#009E73", #green
    "#56B4E9", #blue
    #"#E69F00", #orange
    "#F0E442", #yellow
    "#D55E00"  #red
  ))
  # scale_color_manual(values = c(
  #   # '#228833', #green
  #   # '#66CCEE', #blue
  #   '#CCBB44', #yellow
  #   '#EE6677',  #red~ish
  #   '#AA3377'  #maroon
  #   ))
}

# plot each var of example data
casestudy_plot <- function(v, name, ...){
ggplot(example, aes(x = .data[["it"]], y = .data[[v]])) +
  geom_line(na.rm = TRUE) +
    labs(x = "Iteration number",
         y = name) +
  theme_classic()
}

```

# Missing The Point: Non-Convergence in Iterative Imputation Algorithms

*Notation in this manuscript: *

- square brackets are comments for myself/stuff I need to review

- bullet points are things I need to expand

## Abstract

Iterative imputation is a popular tool to accommodate the ubiquitous problem of missing data. While it is widely accepted that this technique can yield valid inferences, these inferences all rely on algorithmic convergence. Since there is no consensus on how to evaluate the convergence properties iterative imputation algorithms, our study provides insight into identifying non-convergence. We found that--in the cases considered--inferential validity was achieved after five to ten iterations, much earlier than indicated by diagnostic methods. We conclude that it never hurts to iterate longer, but such calculations hardly bring added value.

## Intro

Missing data pose a ubiquitous threat to anyone who aims to obtain unbiased, confidence-valid statistical inferences. A popular technique to accommodate missing data is to 'impute' (i.e., fill in) any missing values in an incomplete dataset. Imputation procedures like 'Multiple Imputation by Chained Equations' (MICE) have proven to be powerful tools to draw valid inference under many missing data circumstances [@rubin87; @buur18]. To obtain imputations, most imputation software packages rely on iterative algorithms.

With iterative imputation, the validity of the inference depends on the state-space of the algorithm at the final iteration. This introduces a potential threat to the validity of the imputations: What if the algorithm has not converged? Are the imputations then to be trusted? And can we rely on the inference obtained using the imputed data? These remain open questions since the convergence properties of iterative imputation algorithms have not been systematically studied (Van Buuren, 2018, 6.5.2). While there is no scientific consensus on how to evaluate the convergence of imputation algorithms [@zhu15; @taka17], the current practice is to visually inspect imputations for signs of non-convergence. 
<!-- (Zhu & Raghunathan, 2015; Takahashi, 2017) -->

Identifying non-convergence through visual inspection may be undesirable for several reasons: 1) it may be challenging to the untrained eye, 2) only severely pathological cases of non-convergence may be diagnosed, and 3) there is not an objective measure that quantifies convergence (Van Buuren, 2018, 6.5.2). Therefore, a quantitative diagnostic method to identify non-convergence would be preferred.

In this paper, we explore diagnostic methods for iterative imputation algorithms. For reasons of brevity, we focus on the iterative imputation algorithm implemented in the popular `mice` package [@mice] in `R` [@R]. We consider two non-convergence identifiers for iterative algorithms: autocorrelation (conform Lynch, 2007, p. 147) and potential scale reduction factor $\widehat{R}$ (conform Vehtari et al., 2019, p. 5). Aside from the usual parameters to monitor---chain means and chain variances---we also investigate convergence in the multivariate state-space of the algorithm.

We propose a novel multivariate parameter to check for non-convergence in iterative algorithms. We aim to show which method is the most informative about non-convergence in iterative imputation [explain that method = parameter + diagnostic + interpretation].

<!-- - Missing data has to be accommodated, usually filled in -->

<!-- - Filling in is algorithmic, which relies on convergence -->

<!-- - Diagnosing convergence is difficult, both visually and diagnostically -->

<!-- - In this paper we explore diagnostic methods for MICE, and show which method (parameter + diagnostic + threshold) is the most informative about convergence  -->

## Identifying non-convergence


-   Iterative imputation is a sort of MCMC algorithm, so it makes sense to investigate non-convergence in a similar fashion to typical MCMC algorithms.

-   What does non-convergence look like? --\> non-stationarity + non-mixing in a certain parameter, e.g., chain means.

-   What are the consequences? --\> bias, under-coverage --\> refer to van Buuren (2018) instead of reproducing this

<!-- -   Existing non-convergence identifiers for MCMC algorithms are not all applicable, e.g. N\_eff is estimated using the variance-covariance matrix of the set of samples, while this is not the case in iterative imputation per se. -->

-   We consider autocorrelation and rhat, and monitor four parameters: chain means, chain variances, a scientific estimate, and lambda.

-   Explain lambda


## Simulation Set-Up

<!-- The aim of the simulation study is to determine the impact of non-convergence on the validity of statistical inferences, and to assess whether non-convergence may be detected using several diagnostic methods. Inferential validity is reached when estimates are both  unbiased and have nominal coverage across simulation repetitions (nsim = 1000). -->

We investigate non-convergence in iterative imputation through model-based simulation in R (version 4.0.3; R Core Team 2020). We provide a summary of the simulation set-up in Algorithm 1; the complete script and technical details are available from [github.com/hanneoberman/MissingThePoint](https://github.com/hanneoberman/MissingThePoint).

**Algorithm 1: simulation set-up (pseudo-code)**

    for each simulation repetition (1:1000)
      1. simulate complete data
      for each missingness condition (1:9)
        2. create missingness
        for each iteration (1:50)
          3. impute missingness
          4. perform analysis of scientific interest
          5. apply non-convergence identifiers
          6. pool results across imputations
          7. compute performance measures
        8. combine outcomes from all iterations
      9. combine outcomes from all missingness conditions
    10. aggregate outcomes from all simulation repetitions

### Aims

With this simulation, we assess the impact of non-convergence on the validity of scientific estimates obtained using `mice` [@mice]. Inferential validity is reached when estimates are both unbiased and have nominal coverage across simulation repetitions ($n_{sim} = 1000$). To induce non-convergence, we terminate the iterative algorithm at different imputation chain lengths ($n_{it} = 1, 2, ..., 50$). We differentiate between nine different missingness scenarios: three missingness mechanisms versus three proportions of incomplete cases [remove here if already defined above/below??].

### Data generating mechanism

Data are generated in each simulation repetition for a complete set of $n_{obs} = 1000$ cases (i.e., before inducing missingness). We define three multivariately normal random variables, let

$$
\begin{pmatrix}
Y\\
X_1\\
X_2
\end{pmatrix}
\sim \mathcal{N}
\begin{bmatrix}
\begin{pmatrix}
0\\
0\\
0
\end{pmatrix},
\begin{pmatrix}
2     &       &  \\
0.5   & 1     &  \\
-0.5  & 0.5   & 1
\end{pmatrix}
\end{bmatrix}.
$$ 

[Add mvtnorm package here??] The complete set is amputed according to nine missingness conditions. We use a $3 \times 3$ factorial design consisting of three missingness mechanisms and three proportions of incomplete cases. [Briefly describe MCAR, MAR, MNAR + 25, 50, 75% of cases incomplete (not using 5% anymore, because according to Vink, n.d., 25% is more representative of missing data problems in the social sciences). And add the `ampute` function?]

### Estimands

We impute the missing data five times ($m = 5$) using Bayesian linear regression imputation with `mice` [@mice]. On each imputed dataset, we perform multiple linear regression to predict outcome variable $Y$ from the other two variables

$$
Y' = \beta_0 + \beta_1 X_1 + \beta_2 X_2,
$$
where $Y'$ is the expected value of the outcome. Our estimands are the regression coefficient $\beta_1$ and coefficient of determination $r^2$ that we obtain after pooling the regression results across the imputations.

### Methods

We use eight different diagnostic methods to identify non-convergence: a combination of two non-convergence identifiers---autocorrelation and $\widehat{R}$---and four parameters of interest---chain means, chain variances, a scientific estimate, and the novel parameter that we propose, $\lambda$.

### Performance measures

As recommended by @buur18, our performance measures are bias ($E(\bar{Q})-Q$), average confidence interval width ($E(\bar{Q}_{LL} - \bar{Q}_{UL})$, where $LL$ and $UL$ denote the lower and upper limit of the 95% confidence interval respectively) and empirical coverage rate ($Pr(\bar{Q}_{LL} \geq Q \geq \bar{Q}_{UL})$) of the estimands [or just of the regression estimate?? otherwise add the ciw and cov of r2 too!! and check if definition of ciw is correct].

## Simulation Results

The following figures provide an overview of the results for each method and each performance measure, contrasted to the number of iterations in the imputation algorithm. Within the figures, we split the results according to the missingness conditions [missingness mechanisms as line types, and proportion of incomplete cases as colors].

### Diagnostic Methods

<!-- The next four plots show the autocorrelations in each parameter plotted against the number of iterations.  -->

```{r echo=FALSE}
p <- simulation_plot(v="ac.max.mu.Y", name = "Autocorrelation chain means")
p # %>% plotly::ggplotly()
```

In this figure, we see autocorrelation in the chain means as the diagnostic method. We can interpret this as the extent to which the average imputed value trends across iterations [unnecessary??]. We observe that autocorrelation in the chain means rapidly decreases until $it \geq 6$. This means that there is some initial trending within chains, but stationarity does not improve substantively after the first few iterations. These results hold irrespective of the missingness condition.

```{r echo=FALSE}
p <- simulation_plot(v="ac.max.sigma.Y", name = "Autocorrelation chain variances")
p # %>% plotly::ggplotly() 
```

Autocorrelation in the chain variances show us something similar. The number of iterations that is required to reach non-improving autocorrelations is somewhat more ambiguous than for chain means, but generally around $it \geq 10$. We do not observe a systematic difference between missingness conditions here either. 

```{r echo=FALSE}
p <- simulation_plot(v="ac.max.qhat", name = "Autocorrelation scientific estimate")
p # %>% plotly::ggplotly() 
```

There is more autocorrelation in the scientific estimates than in the univariate parameters (chain means and chain variances). We observe the highest autocorrelations in conditions where 75% of cases are incomplete. Overall, the autocorrelations reach a plateau when $it \geq 20$ to $30$. There is no clear effect of the missingness mechanisms [unnecessary?].  

```{r echo=FALSE}
p <- simulation_plot(v="ac.max.lambda", name = "Autocorrelation novel theta")
p # %>% plotly::ggplotly() 
```

The autocorrelation in the novel parameter exhibits a similar trend to the autocorrelation in the scientific estimates. Trending in this parameter diminishes when $it \geq 20$.

<!-- The next four plots show the $\widehat{R}$ in the different parameters. -->

```{r echo=FALSE}
p <- simulation_plot(v="r.hat.max.mu.Y", name = "R hat chain means")
p # %>% plotly::ggplotly() 
```

We observe that $\widehat{R}$-values of the chain means generally decreases as a function of the number of iterations. An exception to this observation is the initial increase when $3 \leq it \leq 5$ [interpret?? due to initialization or is there really more mixing initially??]. After the first couple of iterations, the mixing between chain means generally improves until $it \geq 30$ to $40$. There is no apparent differentiation between the missingness conditions. 

```{r echo=FALSE}
p <- simulation_plot(v="r.hat.max.sigma.Y", name = "R hat chain variances")
p # %>% plotly::ggplotly() 
```

The mixing between chain variances mimics the mixing between chain means almost perfectly. Irrespective of the missingness condition, the $\widehat{R}$-values taper off around $it \geq 30$. 

```{r echo=FALSE}
p <- simulation_plot(v="r.hat.max.qhat", name = "R hat scientific estimate")
p # %>% plotly::ggplotly() 
```

With the scientific estimate as parameter we observe very similar $\widehat{R}$-values again. We do, however, see some differences between missingness conditions. Conditions where 75% of the cases are incomplete show more extreme non-mixing. The overall trend remains the same: about 30 iterations are required before mixing stops improving substantially.

```{r echo=FALSE}
p <- simulation_plot(v="r.hat.max.lambda", name = "R hat novel theta")
p # %>% plotly::ggplotly() 
```

$\widehat{R}$-values of the novel parameter show a trend similar to the chain means and chain variances. [add something about conditions??]

[These rhat plots all show some initialization before the fifth iteration: is rhat useful before that??]

### Performance Measures

```{r echo=FALSE}
p <- simulation_plot(v = "est", name = "Bias in regression estimate") + 
  list(geom_hline(yintercept = 0, color = "grey")) 
p # %>% plotly::ggplotly()
```

We see that within a few iterations the average bias approaches zero. When $it \geq 6$, even the worst-performing conditions (e.g., with a proportion of incomplete cases of 75%) produce stable, non-improving estimates [regression coefficient is underestimated because there is less info to estimate the relation??]. 

<!-- Update with different CI computation, see <https://stefvanbuuren.name/fimd/sec-evaluation.html#sec:quantifyingbias> -->

```{r echo=FALSE}
p <- simulation_plot( v ="cov", name = "Coverage rate") + 
  list(geom_hline(yintercept = 0.95, color = "grey"))
p # %>% plotly::ggplotly()

# p <- simulation_plot( v ="cov", name = "Coverage rate") + 
#   list(geom_hline(yintercept = 0.95, color = "grey")) +
#   ylim(0.85, 1)

```

Nominal coverage is quickly reached. After just three iterations, the coverage rates are non-improving in every missingness condition [but MNAR with 5% incomplete cases does not reach nominal coverage --\> due to bias in the estimate in combination with very narrow CI (see CIW!)].

```{r echo=FALSE}
p <- simulation_plot(v="CIW", name = "Average CI width") 
p # %>% plotly::ggplotly()
```

The average confidence interval width decreases quickly with every added iteration until a stable plateau is reached. Depending on the proportion of incomplete cases this takes up-to $it \geq 9$. 

```{r echo=FALSE}
p <- simulation_plot(v="rsq", name = "Bias in coefficient of determination") +
  list(geom_hline(yintercept = 0, color = "grey"))
p # %>% plotly::ggplotly()
```

Equivalent to the bias in the regression estimate, the bias in the coefficient of determination tapers off within a couple of iterations. We observe stable estimates in all conditions when $it \geq 6$ [interpret the over-estimation in MNAR+75% condition?].

<!-- Magnitude of the bias in $r^2$ perfectly follows the missingness mechanisms: least bias for MCAR, most for MNAR. Worst effect of non-convergence for $p=0.95$, MNAR, but stable from it=6. -->


## Discussion

With this study, we show that iterative imputation algorithms can yield correct outcomes, even when a converged state has not yet formally been reached. Any further iterations would then burn computational resources without improving the statistical inferences. 

Our study found that---in the cases considered---inferential validity was achieved after five to ten iterations, much earlier than indicated by the non-convergence identifiers. Of course, it never hurts to iterate longer, but such calculations hardly bring added value.


-   Convergence diagnostics keep improving substantially until it = 20-30

-   Performance measures do not improve after it = 9

-  [methodological explanation is that rhat and ac have a lag (few it to inform your statistic) --\> will always indicate convergence slower than inferential validity is reached]

-   Univariate thetas may under-estimate non-convergence. 

-   Determining non-stationarity with lambda is more difficult than with qhat :(

<!-- ## Check if heuristic for AC works -->

<!-- ```{r} -->

<!-- load("Data/diagnostics.Rdata") -->

<!-- load("Data/raw_outcomes.Rdata") -->

<!-- sim_nr <- 3 -->

<!-- outcomes[[sim_nr]] %>% filter(mech == "MCAR", p == 0.95) %>% ggplot(aes(x=it, y = est)) + geom_line() -->

<!-- convergence_diagnostics %>% filter(sim == sim_nr, mech == "MCAR", p ==0.95) %>% ggplot(aes(x=it, y = ac.max.qhat)) + geom_line() -->

<!-- convergence_diagnostics %>% filter(sim == sim_nr, mech == "MCAR", p ==0.95) %>% ggplot(aes(x=it, y = ac.max.lambda)) + geom_line() -->

<!-- ``` -->

- Idea: calculate rhat for each block of 5 it


## Case Study

- We use real data: the `boys` dataset from the `mice` package

- We are interested in predicting age from the other variables, in particular in the regression coefficient of `hgt`

- We compare non-convergence identified using visual inspection versus rhat in the chain variances, scientific estimate and lambda.

- The figures show results of a `mice` run with 30 iterations but otherwise default settings.


```{r echo=FALSE}
# autocorrelation plots (not used)
# casestudy_plot(v="ac.max.qhat") #+ list(scale_y_continuous(limits = c(0.65,1)))
# casestudy_plot(v="ac.max.lambda")
```

```{r echo=FALSE}
p <- plot(mids)
p[1:2,1] # %>% plotly::ggplotly()
```

From the traceplot of the chain means it seems that mixing improves up-to 20 iterations, and there is some trending up-to 20 iterations as well. The chain variances are more or less stationary after 5 iterations, and mixing requires about 20 iterations.

```{r echo=FALSE}
# p <- casestudy_plot(v="est", name = "Regression estimate")
# p %>% plotly::ggplotly()
```

```{r echo=FALSE}
p <- casestudy_plot(v="r.hat.max.mu.hgt", name = "Rhat chain means") + 
  list(
    geom_hline(yintercept = 1.2, color = "grey")#, 
    #scale_y_continuous(limits = c(1,5))
    )
p # %>% plotly::ggplotly()
```

This figure shows that 36 iterations are required before the $\widehat{R}$-values of the chain means drop below the threshold for non-convergence.

```{r echo=FALSE}
p <-
  casestudy_plot(v = "r.hat.max.qhat", name = "Rhat regression estimate") +
  list(geom_hline(yintercept = 1.2, color = "grey")#,
       #scale_y_continuous(limits = c(1, 2.5))
       )
p # %>% plotly::ggplotly()
```

The scientific estimate reaches the threshold much sooner, when $it=15$.

```{r echo=FALSE}
p <- casestudy_plot(v = "r.hat.max.lambda", name = "Rhat lambda") +
  list(geom_hline(yintercept = 1.2, color = "grey")#,
       #scale_y_continuous(limits = c(1, 2.5))
       )
p # %>% plotly::ggplotly()
```

According to the $\widehat{R}$-values of the novel parameter, at least 25 iterations are required.

[Is this a nice example? Why is convergence so slow? Don't the defaults work? Is this the bmi+wgt+wgt problem? Maybe find an easier problem?]

# References (incomplete)
